import React, { useRef, useEffect, useState } from 'react';
import { useTranslation } from '../contexts/TranslationContext';
import { synthesizeSpeech } from '../services/api';
import { synthesizeSpeechBrowser } from '../services/browserTTS';
import { Play, Pause, Volume2, Download, Settings } from 'lucide-react';
import { formatTime, downloadAudio } from '../services/audioUtils';
import LoadingSpinner from './LoadingSpinner';
import ErrorDisplay from './ErrorDisplay';
import VoiceSelector from './VoiceSelector';

const AudioPlayer: React.FC = () => {
  const { state, dispatch } = useTranslation();
  const [selectedVoice, setSelectedVoice] = useState<string>('');
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [showSettings, setShowSettings] = useState(false);
  const [synthesisTime, setSynthesisTime] = useState(0);
  const [usedBrowserTTS, setUsedBrowserTTS] = useState(false);
  
  const audioRef = useRef<HTMLAudioElement | null>(null);
  const hasPlayedRef = useRef(false);
  const currentAudioUrlRef = useRef<string | null>(null);
  const isProcessingRef = useRef(false);
  const requestIdCounterRef = useRef(0);

  // Voice selection is now handled by VoiceSelector component

  // Synthesize speech when translation is available
  useEffect(() => {
    const synthesizeAudio = async () => {
      if (!state.currentTranslation || !selectedVoice || state.currentTranslation.audioUrl) return;

      // Request deduplication: prevent multiple simultaneous audio generations
      if (isProcessingRef.current) {
        console.log('â­ï¸ Skipping audio generation - already processing');
        return;
      }

      // Increment request ID counter for tracking
      const requestId = ++requestIdCounterRef.current;
      console.log(`ðŸŽµ Starting audio generation request #${requestId}`);

      try {
        isProcessingRef.current = true;
        setIsLoading(true);
        setError(null);
        setUsedBrowserTTS(false);

        const t1 = performance.now();
        
        // Try ElevenLabs first
        try {
          console.log('ðŸ”Š Attempting ElevenLabs synthesis...');
          const result = await synthesizeSpeech(
            state.currentTranslation.translatedText,
            selectedVoice,
            state.targetLanguage
          );
          const synthTime = performance.now() - t1;
          setSynthesisTime(synthTime);

          console.log(`âœ… ElevenLabs synthesis successful in ${(synthTime/1000).toFixed(2)}s`);

          // Update the translation item with audio URL
          const updatedTranslation = {
            ...state.currentTranslation,
            audioUrl: result.audioUrl
          };

          dispatch({ type: 'SET_TRANSLATION', payload: updatedTranslation });

          // Auto-play if enabled - only play once per new audio
          if (state.autoPlay && result.audioUrl !== currentAudioUrlRef.current) {
            // Clean up old audio URL before creating new one
            if (currentAudioUrlRef.current && currentAudioUrlRef.current.startsWith('blob:')) {
              URL.revokeObjectURL(currentAudioUrlRef.current);
              console.log('ðŸ§¹ Cleaned up old audio URL');
            }

            currentAudioUrlRef.current = result.audioUrl;
            hasPlayedRef.current = false; // Reset for new audio
            
            // Clean up old audio first
            if (audioRef.current) {
              audioRef.current.pause();
              audioRef.current.src = '';
            }
            
            // Create new audio instance
            const audio = new Audio(result.audioUrl);
            audioRef.current = audio;
            
            // Set up event listeners
            audio.addEventListener('canplaythrough', () => {
              console.log('âœ… Audio loaded and ready to play');
            });
            
            audio.addEventListener('error', (e) => {
              console.error('âŒ Audio playback error:', e);
            });
            
            // Play only once
            if (!hasPlayedRef.current) {
              hasPlayedRef.current = true;
              audio.load();
              audio.play()
                .then(() => console.log('â–¶ï¸ Audio playing'))
                .catch(err => console.error('âŒ Auto-play failed:', err));
            }
          }
          
        } catch (elevenLabsError) {
          // ElevenLabs failed, try browser TTS
          console.warn('âš ï¸ ElevenLabs failed, falling back to browser TTS:', elevenLabsError);
          
          const synthTime = performance.now() - t1;
          setSynthesisTime(synthTime);
          
          // Use browser TTS
          await synthesizeSpeechBrowser(
            state.currentTranslation.translatedText,
            state.targetLanguage
          );
          
          setUsedBrowserTTS(true);
          console.log('âœ… Browser TTS synthesis successful');
        }

      } catch (error) {
        console.error(`âŒ Audio generation request #${requestId} failed:`, error);
        setError(error instanceof Error ? error.message : 'Failed to generate audio. Please check your configuration.');
      } finally {
        isProcessingRef.current = false;
        setIsLoading(false);
      }
    };

    synthesizeAudio();
  }, [state.currentTranslation, selectedVoice, state.targetLanguage, state.autoPlay, dispatch]);

  // Audio playback functions
  const playAudio = (audioUrl?: string) => {
    const url = audioUrl || state.currentTranslation?.audioUrl;
    if (!url) return;

    // Clean up old audio first
    if (audioRef.current) {
      audioRef.current.pause();
      audioRef.current.src = '';
    }

    // Create new audio instance
    const audio = new Audio(url);
    audioRef.current = audio;
    audio.play().catch(console.error);
  };

  const pauseAudio = () => {
    if (audioRef.current) {
      audioRef.current.pause();
    }
  };

  const handlePlayPause = () => {
    if (state.audioPlayer.isPlaying) {
      pauseAudio();
    } else {
      playAudio();
    }
  };

  const handleVolumeChange = (volume: number) => {
    if (audioRef.current) {
      audioRef.current.volume = volume;
      dispatch({
        type: 'SET_AUDIO_PLAYER_STATE',
        payload: { volume }
      });
    }
  };

  const handlePlaybackRateChange = (rate: number) => {
    if (audioRef.current) {
      audioRef.current.playbackRate = rate;
      dispatch({
        type: 'SET_AUDIO_PLAYER_STATE',
        payload: { playbackRate: rate }
      });
    }
  };

  const handleDownload = () => {
    if (state.currentTranslation?.audioUrl) {
      downloadAudio(
        state.currentTranslation.audioUrl,
        `translation-${Date.now()}.mp3`
      );
    }
  };

  // Audio event handlers
  useEffect(() => {
    const audio = audioRef.current;
    if (!audio) return;

    const handlePlay = () => {
      dispatch({
        type: 'SET_AUDIO_PLAYER_STATE',
        payload: { isPlaying: true }
      });
    };

    const handlePause = () => {
      dispatch({
        type: 'SET_AUDIO_PLAYER_STATE',
        payload: { isPlaying: false }
      });
    };

    const handleTimeUpdate = () => {
      dispatch({
        type: 'SET_AUDIO_PLAYER_STATE',
        payload: {
          currentTime: audio.currentTime,
          duration: audio.duration || 0
        }
      });
    };

    const handleEnded = () => {
      dispatch({
        type: 'SET_AUDIO_PLAYER_STATE',
        payload: { isPlaying: false, currentTime: 0 }
      });
    };

    audio.addEventListener('play', handlePlay);
    audio.addEventListener('pause', handlePause);
    audio.addEventListener('timeupdate', handleTimeUpdate);
    audio.addEventListener('ended', handleEnded);

    return () => {
      audio.removeEventListener('play', handlePlay);
      audio.removeEventListener('pause', handlePause);
      audio.removeEventListener('timeupdate', handleTimeUpdate);
      audio.removeEventListener('ended', handleEnded);
    };
  }, [dispatch]);

  // Cleanup on unmount
  useEffect(() => {
    return () => {
      if (audioRef.current) {
        audioRef.current.pause();
        audioRef.current.src = '';
        audioRef.current = null;
      }
      // Clean up blob URLs to prevent memory leaks
      if (currentAudioUrlRef.current && currentAudioUrlRef.current.startsWith('blob:')) {
        URL.revokeObjectURL(currentAudioUrlRef.current);
      }
    };
  }, []);

  const playbackRates = [0.5, 0.75, 1, 1.25, 1.5, 2];

  return (
    <div className="space-y-4">
      {/* Audio Element */}
      <audio ref={audioRef} preload="none" />

      {/* Playback Controls */}
      <div className="flex items-center justify-center space-x-4">
        <button
          onClick={handlePlayPause}
          disabled={!state.currentTranslation?.audioUrl || isLoading}
          className="flex items-center space-x-2 btn-primary disabled:opacity-50 disabled:cursor-not-allowed"
        >
          {state.audioPlayer.isPlaying ? (
            <Pause className="h-5 w-5" />
          ) : (
            <Play className="h-5 w-5" />
          )}
          <span>
            {state.audioPlayer.isPlaying ? 'Pause' : 'Play'}
          </span>
        </button>

        <button
          onClick={handleDownload}
          disabled={!state.currentTranslation?.audioUrl}
          className="flex items-center space-x-2 px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-700 rounded-lg transition-colors duration-200 disabled:opacity-50 disabled:cursor-not-allowed"
        >
          <Download className="h-5 w-5" />
          <span>Download</span>
        </button>

        <button
          onClick={() => setShowSettings(!showSettings)}
          className="flex items-center space-x-2 px-4 py-2 bg-gray-100 hover:bg-gray-200 text-gray-700 rounded-lg transition-colors duration-200"
        >
          <Settings className="h-5 w-5" />
          <span>Settings</span>
        </button>
      </div>

      {/* Progress Bar */}
      {state.currentTranslation?.audioUrl && (
        <div className="space-y-2">
          <div className="flex justify-between text-xs text-gray-500">
            <span>{formatTime(state.audioPlayer.currentTime)}</span>
            <span>{formatTime(state.audioPlayer.duration)}</span>
          </div>
          <div className="w-full bg-gray-200 rounded-full h-2">
            <div
              className="bg-primary-500 h-2 rounded-full transition-all duration-200"
              style={{
                width: state.audioPlayer.duration > 0
                  ? `${(state.audioPlayer.currentTime / state.audioPlayer.duration) * 100}%`
                  : '0%'
              }}
            />
          </div>
        </div>
      )}

      {/* Settings Panel */}
      {showSettings && (
        <div className="bg-gray-50 rounded-lg p-4 space-y-4">
          {/* Auto-play Toggle */}
          <div className="flex items-center justify-between">
            <label className="text-sm font-medium text-gray-700">
              Auto-play translations
            </label>
            <button
              onClick={() => dispatch({ type: 'TOGGLE_AUTO_PLAY' })}
              className={`relative inline-flex h-6 w-11 items-center rounded-full transition-colors duration-200 ${
                state.autoPlay ? 'bg-primary-500' : 'bg-gray-300'
              }`}
            >
              <span
                className={`inline-block h-4 w-4 transform rounded-full bg-white transition-transform duration-200 ${
                  state.autoPlay ? 'translate-x-6' : 'translate-x-1'
                }`}
              />
            </button>
          </div>

          {/* Voice Selection */}
          <VoiceSelector
            selectedVoice={selectedVoice}
            onVoiceChange={setSelectedVoice}
            language={state.targetLanguage}
          />

          {/* Volume Control */}
          <div>
            <label className="block text-sm font-medium text-gray-700 mb-2">
              Volume: {Math.round(state.audioPlayer.volume * 100)}%
            </label>
            <input
              type="range"
              min="0"
              max="1"
              step="0.1"
              value={state.audioPlayer.volume}
              onChange={(e) => handleVolumeChange(parseFloat(e.target.value))}
              className="w-full"
            />
          </div>

          {/* Playback Speed */}
          <div>
            <label className="block text-sm font-medium text-gray-700 mb-2">
              Playback Speed
            </label>
            <div className="flex space-x-2">
              {playbackRates.map((rate) => (
                <button
                  key={rate}
                  onClick={() => handlePlaybackRateChange(rate)}
                  className={`px-3 py-1 text-sm rounded ${
                    state.audioPlayer.playbackRate === rate
                      ? 'bg-primary-500 text-white'
                      : 'bg-gray-200 text-gray-700 hover:bg-gray-300'
                  }`}
                >
                  {rate}x
                </button>
              ))}
            </div>
          </div>
        </div>
      )}

      {/* Loading State */}
      {isLoading && (
        <div className="flex items-center justify-center py-4">
          <LoadingSpinner />
          <span className="ml-3 text-gray-600">Generating audio...</span>
        </div>
      )}

      {/* Error State */}
      {error && (
        <ErrorDisplay 
          error={error}
          onDismiss={() => setError(null)}
        />
      )}
      
      {/* Browser TTS Indicator */}
      {usedBrowserTTS && !isLoading && (
        <div className="text-sm text-blue-600 bg-blue-50 p-3 rounded-lg text-center">
          âœ… Audio played using free browser text-to-speech
        </div>
      )}
      
      {/* Performance Metrics */}
      {synthesisTime > 0 && !isLoading && !usedBrowserTTS && (
        <div className="text-xs text-gray-500 text-center">
          Audio generated in {(synthesisTime/1000).toFixed(2)}s
        </div>
      )}

      {/* No Audio State */}
      {!state.currentTranslation && (
        <div className="text-center py-8 text-gray-500">
          <Volume2 className="h-12 w-12 mx-auto mb-4 text-gray-300" />
          <p className="text-sm">Audio will appear here after translation</p>
        </div>
      )}
    </div>
  );
};

export default AudioPlayer;
